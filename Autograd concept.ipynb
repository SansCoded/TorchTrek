{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO8oaLId1c7+Z0DLnvMgykh"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Autograd!"
      ],
      "metadata": {
        "id": "kAb6A5zflA-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a tensor with requires_grad=True so PyTorch knows to track operations on it\n",
        "import torch\n",
        "x = torch.tensor(2.0, requires_grad=True)"
      ],
      "metadata": {
        "id": "DREUMhWelIPJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform some operations\n",
        "y = x ** 2 + 3 * x + 5  # y = x^2 + 3x + 5"
      ],
      "metadata": {
        "id": "OTMFxzsEn3o_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, we want to calculate the derivative of y with respect to x, so we call .backward()\n",
        "y.backward()"
      ],
      "metadata": {
        "id": "C68yij48n7_m"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The gradient (dy/dx) is stored in x.grad\n",
        "print(x.grad)  # It will print the derivative of y = 2x + 3 at x = 2, which is 7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "synpUNmvn_OY",
        "outputId": "b1b181da-d135-427c-c877-59eb8029deaa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(7.)\n"
          ]
        }
      ]
    }
  ]
}